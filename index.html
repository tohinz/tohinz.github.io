---
layout: default
title: Tobias Hinz | ML Research Engineer @ Adobe Research
description: I work with generative neural networks to model and understand the world around us.
---

<!-- Overview -->
<section id="overview" class="wrapper style1">
	<div class="container 75%">
		<ul class="row 200%">
			<ul class="6u 12u$(medium)">
				<header class="major">
					<h2>TOBIAS HINZ</h2>
					<div class="image rounded" style="margin-bottom: 2em;"><img src="images/photo.jpg" width="200"
							alt="Avatar" /></div>
					<p style="line-height:1.0">Tech Lead</p>
					<p style="line-height:1.0">Foundational GenAI Models</p>
					<p style="line-height:1.8">Adobe Firefly</p>
				</header>
			</ul>
			<div class="6u$ 12u$(medium)" align="justify">
				<p>I am the tech lead for core foundational models at <a
						href="https://www.adobe.com/sensei/generative-ai/firefly.html" target="_blank">Adobe
						Firefly</a>, responsible for developing the next generation of Generative AI models.
					Previously, I was a Research Engineer at <a href="https://research.adobe.com/" target="_blank">Adobe
						Research</a> where I started the engineering efforts of Adobe Firefly and trained the first
					model that was released.
					Since then, I have led the development and training of the latest foundational imaging and video
					models powering Adobe Firefly's applications across various products and am working with
					teams across Adobe on improving these models to enable great user experiences and ship innovative
					applications.
				</p>
				<p>I obtained my PhD at the <a href="https://www.inf.uni-hamburg.de/en/inst/ab/wtm/"
						target="_blank">Knowledge Technology</a> group at the <a href="https://www.uni-hamburg.de/"
						target="_blank">University of Hamburg</a> (Germany).
					Before that, I completed a research oriented Master's degree in <a
						href="https://www.inf.uni-hamburg.de/studies/master/ias.html" target="_blank">Intelligent
						Adaptive Systems</a> at the University of Hamburg.
					I received a Bachelor's degree in <a href="https://www.wim.uni-mannheim.de/en/business-informatics/"
						target="_blank">Business Informatics</a> at the <a href="https://www.uni-mannheim.de/"
						target="_blank">University of Mannheim</a>, during which I also studied at the <a
						href="http://nus.edu.sg/" target="_blank">National University of Singapore</a> for one semester.
				</p>
			</div>
		</ul>

		<h2 style="text-align: center">News</h2>
		<ul></ul>
		<li>03/2025: Our <a href="https://shotadapter.github.io/" target="_blank">ShotAdapter paper</a> on text-to-multi-shot video generation with diffusion models got accepted to CVPR 2025.</li>
		<li>10/2024: I attended <a href="https://www.adobe.com/max.html" target="_blank">Adobe MAX</a> where Adobe
			announced the public beta of our <a
				href="https://blog.adobe.com/en/publish/2024/10/14/generate-video-beta-on-firefly-web-app"
				target="_blank">text-to-video model</a> as well as <a
				href="https://blog.adobe.com/en/publish/2024/10/14/generative-extend-in-premiere-pro"
				target="_blank">GenExtend</a> (powered by our video model) integrated in Premiere Pro.</li>
		<li>09/2024: A first sneak peek of our foundational <a
				href="https://blog.adobe.com/en/publish/2024/09/11/bringing-gen-ai-to-video-adobe-firefly-video-model-coming-soon"
				target="_blank">text-to-video model</a> at Adobe Firefly that we've been
			working on for the past year.</li>
		<li>06/2024: I attended CVPR 2024 in Seattle. Lots of great papers and conversations.</li>
		<li>03/2024: Our papers on <a
				href="https://openaccess.thecvf.com/content/CVPR2024/html/Ham_Personalized_Residuals_for_Concept-Driven_Text-to-Image_Generation_CVPR_2024_paper.html"
				target="_blank">Personalized T2I</a> and <a
				href="https://openaccess.thecvf.com/content/CVPR2024/html/Li_SNED_Superposition_Network_Architecture_Search_for_Efficient_Video_Diffusion_Model_CVPR_2024_paper.html"
				target="_blank">Efficient Video Diffusion</a> got accepted to CVPR 2024.</li>
		<li>11/2023: I have started leading the efforts on developing foundational text-to-video models for Adobe
			Firefly.</li>
		<li>10/2023: Our second generation of <a href="https://helpx.adobe.com/firefly/using/whats-new/2024.html"
				target="_blank">Firefly</a> models was announced today at the Adobe MAX conference.</li>
		<li>08/2023: Our <a href="https://mcm-diffusion.github.io/" target="_blank">paper on diffusion model
				control</a> was presented at SIGGRAPH.</li>
		<li>07/2023: I received the Adobe Tech Excellence Award, an annual recognition of outstanding technical
			talent for starting the engineering efforts of Adobe's Firefly models, writing more than 80% of the
			initial code base and serving as tech lead for foundational models.</li>
		<li>06/2023: Our <a
				href="https://openaccess.thecvf.com/content/CVPR2023/html/Xie_SmartBrush_Text_and_Shape_Guided_Object_Inpainting_With_Diffusion_Model_CVPR_2023_paper.html"
				target="_blank">paper on inpainting</a> was presented as a highlight at CVPR.</li>
		</ul>
	</div>
</section>

<!-- Shipped Features -->
<section id="blog" class="wrapper style1 special">
	<div class="container">
		<h2 style="text-align: center">Features I Worked On</h2>
		<style>
			.features-grid {
				display: grid;
				grid-template-columns: repeat(2, 1fr);
				gap: 2rem;
				max-width: 1200px;
				margin: 0 auto;
				padding: 1rem;
			}

			.feature-card {
				display: flex;
				align-items: center;
				gap: 1.5rem;
				padding: 1.5rem;
				background: rgba(255, 255, 255, 0.05);
				border-radius: 8px;
			}

			.feature-image {
				flex-shrink: 0;
				width: 150px;
				height: 150px;
				object-fit: cover;
				border-radius: 4px;
			}

			.feature-content {
				flex-grow: 1;
			}

			.feature-content a {
				font-size: 1.1rem;
				font-weight: bold;
				text-decoration: none;
			}

			.feature-content .date {
				font-weight: bold;
				margin: 0.5rem 0;
			}

			.feature-content .description {
				font-size: 0.9rem;
				line-height: 1.4;
			}

			@media (max-width: 768px) {
				.features-grid {
					grid-template-columns: 1fr;
				}

				.feature-card {
					flex-direction: column;
					text-align: center;
				}

				.feature-image {
					width: 120px;
					height: 120px;
				}
			}
		</style>

		<div class="features-grid">
			<div class="feature-card">
				<img class="feature-image" src="images/features/adobe_firefly_video.jpg" alt="Adobe Firefly Video">
				<div class="feature-content">
					<a href="https://blog.adobe.com/en/publish/2024/09/11/bringing-gen-ai-to-video-adobe-firefly-video-model-coming-soon" target="_blank">Adobe Firefly Video Model</a>
					<div class="date">October 2024</div>
					<div class="description">Oversaw technical development of the video model including training of the models and data preparation.</div>
				</div>
			</div>

			<div class="feature-card">
				<img class="feature-image" src="images/features/adobe_genextend.jpg" alt="Adobe GenExtend">
				<div class="feature-content">
					<a href="https://blog.adobe.com/en/publish/2024/10/14/generative-extend-in-premiere-pro" target="_blank">Adobe Firefly Video GenExtend</a>
					<div class="date">October 2024</div>
					<div class="description">Consulted on training and development approaches.</div>
				</div>
			</div>

			<div class="feature-card">
				<img class="feature-image" src="images/features/adobe_firefly.jpg" alt="Adobe Firefly v2">
				<div class="feature-content">
					<a href="https://news.adobe.com/news/news-details/2023/adobe-releases-next-generation-of-firefly-models" target="_blank">Adobe Firefly Image Model v2</a>
					<div class="date">October 2023</div>
					<div class="description">Developed and trained parts of the model; oversaw overall technical development of the core diffusion model.</div>
				</div>
			</div>

			<div class="feature-card">
				<img class="feature-image" src="images/features/adobe_firefly.jpg" alt="Adobe Firefly">
				<div class="feature-content">
					<a href="https://news.adobe.com/news/news-details/2023/adobe-unveils-firefly-a-family-of-new-creative-generative-ai" target="_blank">Adobe Firefly Image Model</a>
					<div class="date">April 2023</div>
					<div class="description">Started the effort that would ultimately result in the foundation of Adobe Firefly; developed and trained the core diffusion model.</div>
				</div>
			</div>
		</div>
	</div>
</section>

<!-- Publications -->
<section id="publications" class="wrapper style2 special">
	<div class="container 75%">
		<h2 style="text-align: center">Selected Publications</h2>
		<p style="text-align:center;">For a full list, have a look at my <a
				href="https://scholar.google.com/citations?user=SugTw28AAAAJ&hl" target="_blank">Google Scholar</a>
			page.</p>
		<hr />

		<ul class="row 150%">
			<ul class="3u 4u(large) 12u$(medium)">
				<div class="image rounded" style="margin-top:1cm;"><img
						src="/images/publication/thumbnails/shotadapter.jpg" width="180" alt=""
						style="border:none;" />
				</div>
			</ul>

			<ul class="9u$ 8u$(large) 12u$(medium)">
				<header>
					<h4>ShotAdapter: Text-to-Multi-Shot Video Generation with Diffusion Models</h4>
					<p>A framework that enables text-to-multi-shot video generation with shot-specific conditioning from a pretrained T2V model.</p>
				</header>
				<p>O. Kara, K. Singh, F. Liu, D. Ceylan, J. M. Rehg, <span style="text-decoration: underline;">T. Hinz</span>, <span
						style="font-weight: bold">Conference on Computer Vision and Pattern Recognition</span> 2025.</p>
				<ul class="btn-group btn-group-sm">
					<a role="button" style="text-decoration: none" class="btn btn-primary"
						href='https://shotadapter.github.io/' target="_blank">Project</a>
					<a role="button" style="text-decoration: none" class="btn btn-primary"
						href='https://arxiv.org/abs/2501.02332' target="_blank">Paper</a>
				</ul>
			</ul>
		</ul>

		<hr />

		<ul class="row 150%">
			<ul class="3u 4u(large) 12u$(medium)">
				<div class="image rounded" style="margin-top:1cm;"><img
						src="/images/publication/thumbnails/pers_residuals.jpg" width="180" alt=""
						style="border:none;" />
				</div>
			</ul>

			<ul class="9u$ 8u$(large) 12u$(medium)">
				<header>
					<h4>Personalized Residuals for Concept-Driven Text-to-Image Generation</h4>
					<p>A novel and efficient approach for enabling personalized image generation with diffusion models.
					</p>
				</header>
				<p>C. Ham, M. Fisher, J. Hays, N. Kolkin, Y. Liu, R. Zhang, <span style="text-decoration: underline;">T.
						Hinz</span>,
					<span style="font-weight: bold">Conference on Computer Vision and Pattern Recognition</span> 2024.
				</p>
				<ul class="btn-group btn-group-sm">
					<a role="button" style="text-decoration: none" class="btn btn-primary"
						href='https://cusuh.github.io/personalized-residuals/' target="_blank">Project</a>
					<a role="button" style="text-decoration: none" class="btn btn-primary"
						href='https://openaccess.thecvf.com/content/CVPR2024/html/Ham_Personalized_Residuals_for_Concept-Driven_Text-to-Image_Generation_CVPR_2024_paper.html'
						target="_blank">Paper</a>
				</ul>
			</ul>
		</ul>

		<hr />

		<ul class="row 150%">
			<ul class="3u 4u(large) 12u$(medium)">
				<div class="image rounded" style="margin-top:1cm;"><img src="/images/publication/thumbnails/mcm.jpg"
						width="180" alt="" style="border:none;" />
				</div>
			</ul>

			<ul class="9u$ 8u$(large) 12u$(medium)">
				<header>
					<h4>Modulating Pretrained Diffusion Models for Multimodal Image Synthesis</h4>
					<p>A multimodal conditioning module (MCM) for enabling conditional image synthesis using pretrained
						diffusion models.</p>
				</header>
				<p>C. Ham, J. Hays, J. Lu, K. Singh, Z. Zhang, <span style="text-decoration: underline;">T. Hinz</span>,
					<span style="font-weight: bold">SIGGRAPH Conference Proceedings</span> 2023.
				</p>
				<ul class="btn-group btn-group-sm">
					<a role="button" style="text-decoration: none" class="btn btn-primary"
						href='https://mcm-diffusion.github.io/' target="_blank">Project</a>
					<a role="button" style="text-decoration: none" class="btn btn-primary"
						href='https://arxiv.org/abs/2302.12764' target="_blank">Paper</a>
				</ul>
			</ul>
		</ul>

		<hr />

		<ul class="row 150%">
			<ul class="3u 4u(large) 12u$(medium)">
				<div class="image rounded" style="margin-top:1cm;"><img
						src="/images/publication/thumbnails/smartbrush.jpg" width="180" alt="" style="border:none;" />
				</div>
			</ul>

			<ul class="9u$ 8u$(large) 12u$(medium)">
				<header>
					<h4>SmartBrush: Text and Shape Guided Object Inpainting with Diffusion Model</h4>
					<p>A diffusion model for shape-guided inpainting with better shape control and background
						preservation within the inpainted region.</p>
				</header>
				<p>S. Xie, Z. Zhang, Z. Lin, <span style="text-decoration: underline;">T. Hinz</span>, K. Zhang, <span
						style="font-weight: bold">Conference on Computer Vision and Pattern Recognition</span> 2023.</p>
				<ul class="btn-group btn-group-sm">
					<a role="button" style="text-decoration: none" class="btn btn-primary"
						href='https://arxiv.org/abs/2212.05034' target="_blank">Paper</a>
				</ul>
			</ul>
		</ul>

		<hr />

		<ul class="row 150%">
			<ul class="3u 4u(large) 12u$(medium)">
				<div class="image rounded" style="margin-top:1cm;"><img src="/images/publication/thumbnails/asset.jpg"
						width="180" alt="" style="border:none;" /></div>
			</ul>

			<ul class="9u$ 8u$(large) 12u$(medium)">
				<header>
					<h4>ASSET: Autoregressive Semantic Scene Editing with Transformers at High Resolutions</h4>
					<p>A neural architecture for automatically modifying an input high-resolution image according to a
						user's edits on its semantic segmentation map.</p>
				</header>
				<p>D. Liu, S. Shetty, <span style="text-decoration: underline;">T. Hinz</span>, M. Fisher,
					R. Zhang, T. Park, E. Kalogerakis, <span style="font-weight: bold">ACM Transactions on Graphics
						(SIGGRAPH 2022)</span> 2022.</p>
				<ul class="btn-group btn-group-sm">
					<a role="button" style="text-decoration: none" class="btn btn-primary"
						href='https://people.cs.umass.edu/~dliu/projects/ASSET/' target="_blank">Project</a>
					<a role="button" style="text-decoration: none" class="btn btn-primary"
						href='https://github.com/DifanLiu/ASSET' target="_blank">Code</a>
				</ul>
			</ul>
		</ul>

		<hr />

		<ul class="row 150%">
			<ul class="3u 4u(large) 12u$(medium)">
				<div class="image rounded" style="margin-top:1cm;"><img
						src="/images/publication/thumbnails/consingan.jpg" width="180" alt="" style="border:none;" />
				</div>
			</ul>

			<ul class="9u$ 8u$(large) 12u$(medium)">
				<header>
					<h4>Improved Techniques for Training Single-Image GANs</h4>
					<p>Improving the results and training speed of single-image GANs.</p>
				</header>
				<p><span style="text-decoration: underline;">T. Hinz</span>, M. Fisher, O. Wang, S. Wermter, <span
						style="font-weight: bold">IEEE Winter Conference on Applications of Computer Vision</span> 2021.
				</p>
				<ul class="btn-group btn-group-sm">
					<a role="button" style="text-decoration: none" class="btn btn-primary"
						href='https://arxiv.org/abs/2003.11512' target="_blank">Paper</a>
					<a role="button" style="text-decoration: none" class="btn btn-primary"
						href='/2020/03/24/improved-techniques-for-training-single-image-gans'>Blog Post</a>
					<a role="button" style="text-decoration: none" class="btn btn-primary"
						href='https://github.com/tohinz/ConSinGAN' target="_blank">Code</a>
				</ul>
			</ul>
		</ul>

		<hr />

		<ul class="row 150%">
			<ul class="3u 4u(large) 12u$(medium)">
				<div class="image rounded" style="margin-top:1cm;"><img
						src="/images/publication/thumbnails/soa-for-tti.jpg" width="180" alt="" style="border:none;" />
				</div>
			</ul>

			<ul class="9u$ 8u$(large) 12u$(medium)">
				<header>
					<h4>Semantic Object Accuracy for Generative Text-to-Image Synthesis</h4>
					<p>A novel GAN architecture and an improved metric to evaluate generative text-to-image synthesis
						models.</p>
				</header>
				<p><span style="text-decoration: underline;">T. Hinz</span>, S. Heinrich, S. Wermter, <span
						style="font-weight: bold">IEEE Transactions on Pattern Analysis and Machine Intelligence</span>
					2020.</p>
				<ul class="btn-group btn-group-sm">
					<a role="button" style="text-decoration: none" class="btn btn-primary"
						href='https://ieeexplore.ieee.org/document/9184960' target="_blank">Paper</a>
					<a role="button" style="text-decoration: none" class="btn btn-primary"
						href='/2019/10/30/semantic-object-accuracy-for-generative-text-to-image-synthesis'>Blog Post</a>
					<a role="button" style="text-decoration: none" class="btn btn-primary"
						href='https://github.com/tohinz/semantic-object-accuracy-for-generative-text-to-image-synthesis'
						target="_blank">Code</a>
				</ul>
			</ul>
		</ul>

		<hr />

		<ul class="row 150%">
			<ul class="3u 4u(large) 12u$(medium)">
				<div class="image rounded" style="margin-top:1cm;"><img src="/images/publication/thumbnails/mogan.jpg"
						width="180" alt="" style="border:none;" /></div>
			</ul>

			<ul class="9u$ 8u$(large) 12u$(medium)">
				<header>
					<h4>Generating Multiple Objects at Spatially Distinct Locations</h4>
					<p>Fine-grained control over the placement and identity of objects in images generated with a
						Generative Adversarial Network.</p>
				</header>
				<p><span style="text-decoration: underline;">T. Hinz</span>, S. Heinrich, S. Wermter, <span
						style="font-weight: bold">International Conference on Learning Representations</span> 2019.</p>
				<ul class="btn-group btn-group-sm">
					<a role="button" style="text-decoration: none" class="btn btn-primary"
						href='https://openreview.net/forum?id=H1edIiA9KQ' target="_blank">Paper</a>
					<a role="button" style="text-decoration: none" class="btn btn-primary"
						href='/2019/01/09/generating-multiple-objects-at-spatially-distinct-locations'>Blog Post</a>
					<a role="button" style="text-decoration: none" class="btn btn-primary"
						href='https://github.com/tohinz/multiple-objects-gan' target="_blank">Code</a>
				</ul>
			</ul>
		</ul>
		<br>
		<hr />
		<a href="/publications/index" class="btn btn-primary btn-lg" role="button" style="text-decoration: none">See
			All</a>
	</div>
</section>

<!-- Blog -->
<section id="blog" class="wrapper style1 special">
	<div class="container 75%">
		{% for page in site.posts %}
		<ul class="row 150%">
			<ul class="3u 4u(large) 12u$(medium)">
				<div class="image rounded" style="margin-top:1cm;"><a href="{{ page.url }}"><img
							src="{{ page.thumbnail }}" width="180" alt="" style="border:none;" /></a></div>
			</ul>

			<ul class="9u$ 8u$(large) 12u$(medium)">
				<header>
					<h4><a href="{{ page.url }}">{{ page.title }}</a></h4>
					<p>Posted on {{ page.date | date: "%d %b %Y" }} | Reading time: {% include read_time.html %}</p>
				</header>
				<p>{{ page.description }}</p>
				<p><a class="btn btn-primary btn-sm" role="button" style="text-decoration: none"
						href="{{ page.url }}">Continue reading</a></p>
			</ul>
		</ul>
		{% if forloop.index == 4 %}
		{% break %}
		{% endif %}
		{% endfor %}
		<hr />
		<a href="/blog/index" class="btn btn-primary btn-lg" role="button" style="text-decoration: none">See All</a>
		<br>
	</div>
</section>

<!-- CV -->
<section id="cv" class="wrapper style2 special">
	<div class="container 50%">
		<h2>Curriculum Vitae</h2>
		<ul class="actions">
			<li><a href="documents/CV_Tobias_Hinz.pdf" class="btn btn-primary btn-lg" role="button"
					style="text-decoration: none" target="_blank">Download CV</a></li>
		</ul>
	</div>
</section>